{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import GPUtil\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import torch.nn as nn\n",
    "import pennylane as qml\n",
    "from typing import List\n",
    "from qudit_mapping import *\n",
    "from qutrit_synthesis import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from itertools import combinations\n",
    "import torch.distributions as dists\n",
    "from scipy.linalg import norm, orth\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.sparse import csr_matrix, eye\n",
    "\n",
    "np.set_printoptions(precision=8, linewidth=200)\n",
    "torch.set_printoptions(precision=8, linewidth=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_state_energy = -4\n",
    "energy_mean = torch.arange(-4, 4, 1e-3)\n",
    "coeff = (energy_mean - ground_state_energy).ceil()\n",
    "plt.plot(energy_mean, coeff)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = 4\n",
    "coeff_funcs = [\n",
    "    lambda cos_sim: coeff * cos_sim,\n",
    "    lambda cos_sim: coeff * cos_sim.pow(2),\n",
    "    lambda cos_sim: coeff * (2 * cos_sim - cos_sim.pow(2)),\n",
    "    lambda cos_sim: coeff / 10 * (10 * cos_sim).ceil()\n",
    "]\n",
    "cos_sim = torch.arange(-1, 1, 1e-3)\n",
    "\n",
    "for coeff_func in coeff_funcs:\n",
    "    plt.plot(cos_sim, torch.where(cos_sim > 0, coeff_func(cos_sim), 0))\n",
    "plt.xticks(np.linspace(-1, 1, 11))\n",
    "plt.yticks(np.linspace(0, coeff, 11))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import GPUtil\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import pennylane as qml\n",
    "from typing import List\n",
    "from utils import fidelity\n",
    "from scipy.io import loadmat\n",
    "import torch.nn.functional as F\n",
    "from itertools import combinations\n",
    "import torch.distributions as dists\n",
    "from torch.utils.data import DataLoader\n",
    "from qutrit_synthesis import NUM_PR, two_qutrit_unitary_synthesis\n",
    "\n",
    "np.set_printoptions(precision=15, linewidth=200)\n",
    "torch.set_printoptions(precision=15, linewidth=200)\n",
    "\n",
    "n_test = 1\n",
    "name = 'VGON_nqd7_20241020_215744'\n",
    "if True:\n",
    "    load = loadmat(f'./mats/{name}.mat')\n",
    "    n_qudits = load['n_qudits'].item()\n",
    "    n_qubits = load['n_qubits'].item()\n",
    "    batch_size = load['batch_size'].item()\n",
    "\n",
    "    n_layers = 2\n",
    "    beta = -1 / 3\n",
    "    n_samples = batch_size * n_test\n",
    "    n_params = n_layers * (n_qudits - 1) * NUM_PR\n",
    "\n",
    "    z_dim = 50\n",
    "    list_z = np.arange(np.floor(np.log2(n_params)), np.ceil(np.log2(z_dim)) - 1, -1)\n",
    "    h_dim = np.power(2, list_z).astype(int)\n",
    "\n",
    "    dev = qml.device('default.qubit', n_qubits)\n",
    "    gpu_memory = gpu[0].memoryUtil if (gpu := GPUtil.getGPUs()) else 1\n",
    "    if torch.cuda.is_available() and gpu_memory < 0.5 and n_qubits >= 14:\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    def spin_operator(obj: List[int]):\n",
    "        if len(obj) != 2:\n",
    "            raise ValueError(f'The number of object qubits {len(obj)} should be 2')\n",
    "        sx = qml.X(obj[0]) + qml.X(obj[1])\n",
    "        sy = qml.Y(obj[0]) + qml.Y(obj[1])\n",
    "        sz = qml.Z(obj[0]) + qml.Z(obj[1])\n",
    "        return sx, sy, sz\n",
    "\n",
    "    def spin_operator2(obj: List[int]):\n",
    "        if len(obj) != 2:\n",
    "            raise ValueError(f'The number of object qubits {len(obj)} should be 2')\n",
    "        s1 = spin_operator(obj)\n",
    "        s2 = [i @ j for i in s1 for j in s1]\n",
    "        return s2\n",
    "\n",
    "    def Hamiltonian(n_qudits: int, beta: float):\n",
    "        ham1, ham2 = 0, 0\n",
    "        for i in range(n_qudits - 1):\n",
    "            obj1 = [2 * i, 2 * i + 1]\n",
    "            obj2 = [2 * i + 2, 2 * i + 3]\n",
    "            ham1 += qml.sum(*[spin_operator(obj1)[i] @ spin_operator(obj2)[i] for i in range(3)])\n",
    "            ham2 += qml.sum(*[spin_operator2(obj1)[i] @ spin_operator2(obj2)[i] for i in range(9)])\n",
    "        ham = ham1 / 4 - beta * ham2 / 16\n",
    "        coeffs, obs = qml.simplify(ham).terms()\n",
    "        coeffs = torch.tensor(coeffs).real\n",
    "        return qml.Hamiltonian(coeffs, obs)\n",
    "\n",
    "    def qutrit_symmetric_ansatz(params: torch.Tensor):\n",
    "        for i in range(n_qudits - 1):\n",
    "            obj = list(range(n_qubits - 2 * i - 4, n_qubits - 2 * i))\n",
    "            two_qutrit_unitary_synthesis(params[i], obj)\n",
    "\n",
    "    @qml.qnode(dev, interface='torch', diff_method='best')\n",
    "    def circuit_state(n_layers: int, params: torch.Tensor):\n",
    "        params = params.transpose(0, 1).reshape(n_layers, n_qudits - 1, NUM_PR, batch_size)\n",
    "        qml.layer(qutrit_symmetric_ansatz, n_layers, params)\n",
    "        return qml.state()\n",
    "\n",
    "    @qml.qnode(dev, interface='torch', diff_method='best')\n",
    "    def circuit_expval(n_layers: int, params: torch.Tensor, Ham):\n",
    "        params = params.transpose(0, 1).reshape(n_layers, n_qudits - 1, NUM_PR, batch_size)\n",
    "        qml.layer(qutrit_symmetric_ansatz, n_layers, params)\n",
    "        return qml.expval(Ham)\n",
    "\n",
    "    class VAE_Model(nn.Module):\n",
    "\n",
    "        def __init__(self, n_params: int, z_dim: int, h_dim: List[int]):\n",
    "            super(VAE_Model, self).__init__()\n",
    "            # encoder\n",
    "            self.e1 = nn.ModuleList([nn.Linear(n_params, h_dim[0], bias=True)])\n",
    "            self.e1 += [nn.Linear(h_dim[i - 1], h_dim[i], bias=True) for i in range(1, len(h_dim))]\n",
    "            self.e2 = nn.Linear(h_dim[-1], z_dim, bias=True)\n",
    "            self.e3 = nn.Linear(h_dim[-1], z_dim, bias=True)\n",
    "            # decoder\n",
    "            self.d4 = nn.ModuleList([nn.Linear(z_dim, h_dim[-1], bias=True)])\n",
    "            self.d4 += [nn.Linear(h_dim[-i + 1], h_dim[-i], bias=True) for i in range(2, len(h_dim) + 1)]\n",
    "            self.d5 = nn.Linear(h_dim[0], n_params, bias=True)\n",
    "\n",
    "        def encoder(self, x):\n",
    "            h = F.relu(self.e1[0](x))\n",
    "            for i in range(1, len(self.e1)):\n",
    "                h = F.relu(self.e1[i](h))\n",
    "            mean = self.e2(h)\n",
    "            log_var = self.e3(h)\n",
    "            return mean, log_var\n",
    "\n",
    "        def reparameterize(self, mean, log_var):\n",
    "            eps = torch.randn(log_var.shape).to(device)\n",
    "            std = torch.exp(log_var).pow(0.5)\n",
    "            z = mean + std * eps\n",
    "            return z\n",
    "\n",
    "        def decoder(self, z):\n",
    "            params = F.relu(self.d4[0](z))\n",
    "            for i in range(1, len(self.d4)):\n",
    "                params = F.relu(self.d4[i](params))\n",
    "            params = self.d5(params)\n",
    "            return params\n",
    "\n",
    "        def forward(self, x):\n",
    "            mean, log_var = self.encoder(x)\n",
    "            z = self.reparameterize(mean, log_var)\n",
    "            params = self.decoder(z)\n",
    "            return params, mean, log_var\n",
    "\n",
    "    state_dict = torch.load(f'./mats/{name}.pt', map_location=device, weights_only=True)\n",
    "    model = VAE_Model(n_params, z_dim, h_dim).to(device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "\n",
    "    data_dist = dists.Uniform(0, 1).sample([n_samples, n_params])\n",
    "    test_data = DataLoader(data_dist, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    Ham = Hamiltonian(n_qudits, beta)\n",
    "for i, batch in enumerate(test_data):\n",
    "    param, _, _ = model(batch.to(device))\n",
    "\n",
    "    cos_sims = torch.empty((0), device=device)\n",
    "    for ind in combinations(range(batch_size), 2):\n",
    "        sim = torch.cosine_similarity(param[ind[0], :], param[ind[1], :], dim=0)\n",
    "        cos_sims = torch.cat((cos_sims, sim.unsqueeze(0)), dim=0)\n",
    "    print(f'Cos_Sim: {cos_sims.mean():.15f}, {cos_sims.max():.12f}, {cos_sims.min():.12f}')\n",
    "\n",
    "    state = circuit_state(n_layers, param)\n",
    "    fidelities = torch.empty((0), device=device)\n",
    "    for ind in combinations(range(batch_size), 2):\n",
    "        fidelity = qml.math.fidelity_statevector(state[ind[0]], state[ind[1]])\n",
    "        fidelities = torch.cat((fidelities, fidelity.unsqueeze(0)), dim=0)\n",
    "    print(f'Fidelity: {fidelities.mean():.15f}, {fidelities.max():.12f}, {fidelities.min():.12f}')\n",
    "\n",
    "    energy = circuit_expval(n_layers, param, Ham)\n",
    "    print(f'Energy: {energy.mean():.15f}, {energy.max():.12f}, {energy.min():.12f}')\n",
    "\n",
    "    for i, ind in enumerate(combinations(range(batch_size), 2)):\n",
    "        print(f'{ind}: Cos_Sim: {cos_sims[i]:.15f}, Fidelity: {fidelities[i]:.15f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import GPUtil\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import pennylane as qml\n",
    "from typing import List\n",
    "import torch.nn.functional as F\n",
    "from itertools import combinations\n",
    "import torch.distributions as dists\n",
    "from torch.utils.data import DataLoader\n",
    "from qutrit_synthesis import NUM_PR, two_qutrit_unitary_synthesis\n",
    "\n",
    "np.set_printoptions(precision=15, linewidth=200)\n",
    "torch.set_printoptions(precision=15, linewidth=200)\n",
    "\n",
    "n_iter = 100\n",
    "n_qudits = 4\n",
    "if True:\n",
    "    n_layers = 2\n",
    "    batch_size = 1\n",
    "    n_qubits = 2 * n_qudits\n",
    "    n_samples = batch_size * n_iter\n",
    "    n_params = n_layers * (n_qudits - 1) * NUM_PR\n",
    "\n",
    "    z_dim = 50\n",
    "    list_z = np.arange(np.floor(np.log2(n_params)), np.ceil(np.log2(z_dim)) - 1, -1)\n",
    "    h_dim = np.power(2, list_z).astype(int)\n",
    "\n",
    "    dev = qml.device('default.qubit', n_qubits)\n",
    "    gpu_memory = gpu[0].memoryUtil if (gpu := GPUtil.getGPUs()) else 1\n",
    "    if torch.cuda.is_available() and gpu_memory < 0.5 and n_qubits >= 14:\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    print(f'PyTorch Device: {device}')\n",
    "\n",
    "    def qutrit_symmetric_ansatz(params: torch.Tensor):\n",
    "        for i in range(n_qudits - 1):\n",
    "            obj = list(range(n_qubits - 2 * i - 4, n_qubits - 2 * i))\n",
    "            two_qutrit_unitary_synthesis(params[i], obj)\n",
    "\n",
    "    @qml.qnode(dev, interface='torch', diff_method='best')\n",
    "    def circuit_state_init(n_layers: int, params: torch.Tensor):\n",
    "        params = params.reshape(n_layers, n_qudits - 1, NUM_PR)\n",
    "        qml.layer(qutrit_symmetric_ansatz, n_layers, params)\n",
    "        return qml.state()\n",
    "\n",
    "    @qml.qnode(dev, interface='torch', diff_method='best')\n",
    "    def circuit_state(n_layers: int, params: torch.Tensor):\n",
    "        params = params.transpose(0, 1).reshape(n_layers, n_qudits - 1, NUM_PR, batch_size)\n",
    "        qml.layer(qutrit_symmetric_ansatz, n_layers, params)\n",
    "        return qml.state()\n",
    "\n",
    "    class VAE_Model(nn.Module):\n",
    "\n",
    "        def __init__(self, n_params: int, z_dim: int, h_dim: List[int]):\n",
    "            super(VAE_Model, self).__init__()\n",
    "            # encoder\n",
    "            self.e1 = nn.ModuleList([nn.Linear(n_params, h_dim[0], bias=True)])\n",
    "            self.e1 += [nn.Linear(h_dim[i - 1], h_dim[i], bias=True) for i in range(1, len(h_dim))]\n",
    "            self.e2 = nn.Linear(h_dim[-1], z_dim, bias=True)\n",
    "            self.e3 = nn.Linear(h_dim[-1], z_dim, bias=True)\n",
    "            # decoder\n",
    "            self.d4 = nn.ModuleList([nn.Linear(z_dim, h_dim[-1], bias=True)])\n",
    "            self.d4 += [nn.Linear(h_dim[-i + 1], h_dim[-i], bias=True) for i in range(2, len(h_dim) + 1)]\n",
    "            self.d5 = nn.Linear(h_dim[0], n_params, bias=True)\n",
    "\n",
    "        def encoder(self, x):\n",
    "            h = F.relu(self.e1[0](x))\n",
    "            for i in range(1, len(self.e1)):\n",
    "                h = F.relu(self.e1[i](h))\n",
    "            mean = self.e2(h)\n",
    "            log_var = self.e3(h)\n",
    "            return mean, log_var\n",
    "\n",
    "        def reparameterize(self, mean, log_var):\n",
    "            eps = torch.randn(log_var.shape).to(device)\n",
    "            std = torch.exp(log_var).pow(0.5)\n",
    "            z = mean + std * eps\n",
    "            return z\n",
    "\n",
    "        def decoder_expval(self, z):\n",
    "            params = F.relu(self.d4[0](z))\n",
    "            for i in range(1, len(self.d4)):\n",
    "                params = F.relu(self.d4[i](params))\n",
    "            params = self.d5(params)\n",
    "            return circuit_expval(n_layers, params, Ham)\n",
    "\n",
    "        def decoder(self, z):\n",
    "            params = F.relu(self.d4[0](z))\n",
    "            for i in range(1, len(self.d4)):\n",
    "                params = F.relu(self.d4[i](params))\n",
    "            params = self.d5(params)\n",
    "            return params\n",
    "\n",
    "        def forward(self, x):\n",
    "            mean, log_var = self.encoder(x)\n",
    "            z = self.reparameterize(mean, log_var)\n",
    "            params = self.decoder(z)\n",
    "            return params, mean, log_var\n",
    "\n",
    "    param_init = torch.Tensor(np.random.uniform(0, 1, n_params))\n",
    "    state_init = circuit_state_init(n_layers, param_init).to(device)\n",
    "\n",
    "    model = VAE_Model(n_params, z_dim, h_dim).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    data_dist = dists.Uniform(0, 1).sample([n_samples, n_params])\n",
    "    train_data = DataLoader(data_dist, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    params = torch.empty((0), device=device)\n",
    "    states = torch.empty((0), device=device)\n",
    "    fidelities = torch.empty((0), device=device)\n",
    "for i, batch in enumerate(train_data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    param, _, _ = model(batch.to(device))\n",
    "    params = torch.cat((params, param), dim=0)\n",
    "\n",
    "    state = circuit_state(n_layers, param)\n",
    "    states = torch.cat((states, state), dim=0)\n",
    "\n",
    "    fidelity = qml.math.fidelity_statevector(state_init, state)\n",
    "    fidelities = torch.cat((fidelities, fidelity), dim=0)\n",
    "\n",
    "    loss = fidelity.squeeze(0)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (i + 1) % 10 == 0:\n",
    "        t = time.perf_counter() - start\n",
    "        print(f'Loss: {loss:.15f}, {loss:.8e}, {i+1}/{n_iter}, {t:.2f}')\n",
    "f_sort, f_ind = fidelities.sort()\n",
    "f_sort, f_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_div(p, q):\n",
    "    p = torch.softmax(p, dim=0)\n",
    "    q = torch.softmax(q, dim=0)\n",
    "    return (p * (p.log2() - q.log2())).sum().unsqueeze(0)\n",
    "\n",
    "\n",
    "def JS_div(p, q):\n",
    "    p = torch.softmax(p, dim=0)\n",
    "    q = torch.softmax(q, dim=0)\n",
    "    return (p * p.log2() / 2 + q * q.log2() / 2 - (p + q) * ((p + q) / 2).log2() / 2).sum().unsqueeze(0)\n",
    "\n",
    "\n",
    "def H_distance(p, q):\n",
    "    p = torch.softmax(p, dim=0)\n",
    "    q = torch.softmax(q, dim=0)\n",
    "    return ((p.sqrt() - q.sqrt()).pow(2).sum() / 2).sqrt().unsqueeze(0)\n",
    "\n",
    "\n",
    "KL_divs = torch.empty((0), device=device)\n",
    "JS_divs = torch.empty((0), device=device)\n",
    "cos_sims = torch.empty((0), device=device)\n",
    "H_dist = torch.empty((0), device=device)\n",
    "for i in range(n_iter):\n",
    "    cos_sim = torch.cosine_similarity(param_init, params[i], dim=0)\n",
    "    cos_sims = torch.cat((cos_sims, cos_sim.unsqueeze(0)), dim=0)\n",
    "    KL_divs = torch.cat((KL_divs, KL_div(param_init, params[i])), dim=0)\n",
    "    JS_divs = torch.cat((JS_divs, JS_div(param_init, params[i])), dim=0)\n",
    "    H_dist = torch.cat((H_dist, H_distance(param_init, params[i])), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot(x: torch.Tensor, label: str):\n",
    "    plt.plot(np.arange(n_iter), x.detach().numpy(), label=label)\n",
    "\n",
    "\n",
    "plot(f_sort, 'Fidelity')\n",
    "# plot(cos_sims[f_ind], 'Cos_Sim')\n",
    "plot(KL_divs[f_ind], 'KL_div')\n",
    "plot(JS_divs[f_ind], 'JS_div')\n",
    "plot(H_dist[f_ind], 'H_dist')\n",
    "plt.xticks(np.linspace(0, n_iter, 11))\n",
    "# plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qutrit_spin_operator(n_qudits: int, is_csr: bool = False):\n",
    "    ss = csr_matrix((3**n_qudits, 3**n_qudits), dtype=CDTYPE)\n",
    "    for i in range(n_qudits - 1):\n",
    "        d1, d2 = 3**i, 3**(n_qudits - i - 2)\n",
    "        for j in s_list:\n",
    "            ss += tensor_product_sparse(eye(d1), j, j, eye(d2))\n",
    "    if is_csr:\n",
    "        return ss\n",
    "    return ss.toarray()\n",
    "\n",
    "\n",
    "def qutrit_spin_operator2(n_qudits: int, is_csr: bool = False):\n",
    "    ss = csr_matrix((3**n_qudits, 3**n_qudits), dtype=CDTYPE)\n",
    "    for i in range(n_qudits - 1):\n",
    "        d1, d2 = 3**i, 3**(n_qudits - i - 2)\n",
    "        for j in s2_list:\n",
    "            ss += tensor_product_sparse(eye(d1), j, j, eye(d2))\n",
    "    if is_csr:\n",
    "        return ss\n",
    "    return ss.toarray()\n",
    "\n",
    "\n",
    "def qutrit_Hamiltonian(n_qudits: int, beta: float, is_csr: bool = False):\n",
    "    s1 = qutrit_spin_operator(n_qudits, is_csr=True)\n",
    "    s2 = qutrit_spin_operator2(n_qudits, is_csr=True)\n",
    "    Ham = s1 - beta * s2\n",
    "    if is_csr:\n",
    "        return Ham\n",
    "    return Ham.toarray()\n",
    "\n",
    "\n",
    "sx = csr_matrix([[0, 1, 0], [1, 0, 1], [0, 1, 0]]) / np.sqrt(2)\n",
    "sy = csr_matrix([[0, -1j, 0], [1j, 0, -1j], [0, 1j, 0]]) / np.sqrt(2)\n",
    "sz = csr_matrix([[1, 0, 0], [0, 0, 0], [0, 0, -1]])\n",
    "s_list = [sx, sy, sz]\n",
    "s2_list = [i @ j for i in s_list for j in s_list]\n",
    "sym_list = [symmetric_encoding(i, is_csr=True) for i in s_list]\n",
    "sym2_list = [i @ j for i in sym_list for j in sym_list]\n",
    "\n",
    "beta = -1 / 3\n",
    "n_qudits = 10\n",
    "n_qubits = 2 * n_qudits\n",
    "t1 = time.perf_counter()\n",
    "ham = qutrit_Hamiltonian(n_qudits, beta, is_csr=True)\n",
    "t2 = time.perf_counter()\n",
    "print('Time:', t2 - t1)\n",
    "eigvals, eigvecs = eigsh(ham, k=4, which='SA')\n",
    "t3 = time.perf_counter()\n",
    "print('Time:', t3 - t2)\n",
    "eigvecs = orth(eigvecs)\n",
    "t4 = time.perf_counter()\n",
    "print('Time:', t4 - t3)\n",
    "\n",
    "for name in range(len(eigvals)):\n",
    "    print(np.allclose(ham @ eigvecs[:, name], eigvals[name] * eigvecs[:, name], atol=1e-14), norm(eigvecs[:, name], 2), eigvals)\n",
    "for name in combinations(range(len(eigvals)), 2):\n",
    "    print(name, fidelity(eigvecs[:, name[0]], eigvecs[:, name[1]]))\n",
    "t5 = time.perf_counter()\n",
    "print('Time:', t5 - t4)\n",
    "\n",
    "mat_path = f'./mats/ED_degeneracy.mat'\n",
    "# updatemat(mat_path, {f'nqd{n_qudits}': (eigvals, eigvecs)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spin_operator(obj: List[int]):\n",
    "    if len(obj) != 2:\n",
    "        raise ValueError(f'The number of object qubits {len(obj)} should be 2')\n",
    "    sx = qml.X(obj[0]) + qml.X(obj[1])\n",
    "    sy = qml.Y(obj[0]) + qml.Y(obj[1])\n",
    "    sz = qml.Z(obj[0]) + qml.Z(obj[1])\n",
    "    return sx, sy, sz\n",
    "\n",
    "\n",
    "def spin_operator2(obj: List[int]):\n",
    "    if len(obj) != 2:\n",
    "        raise ValueError(f'The number of object qubits {len(obj)} should be 2')\n",
    "    s1 = spin_operator(obj)\n",
    "    s2 = [i @ j for i in s1 for j in s1]\n",
    "    return s2\n",
    "\n",
    "\n",
    "def Hamiltonian(n_qudits: int, beta: float):\n",
    "    ham1, ham2 = 0, 0\n",
    "    for i in range(n_qudits - 1):\n",
    "        obj1 = [2 * i, 2 * i + 1]\n",
    "        obj2 = [2 * i + 2, 2 * i + 3]\n",
    "        ham1 += qml.sum(*[spin_operator(obj1)[i] @ spin_operator(obj2)[i] for i in range(3)])\n",
    "        ham2 += qml.sum(*[spin_operator2(obj1)[i] @ spin_operator2(obj2)[i] for i in range(9)])\n",
    "    Ham = ham1 / 4 - beta * ham2 / 16\n",
    "    coeffs, obs = qml.simplify(Ham).terms()\n",
    "    coeffs = torch.tensor(coeffs).real\n",
    "    Ham = qml.Hamiltonian(coeffs, obs)\n",
    "    return Ham\n",
    "\n",
    "\n",
    "def qutrit_spin_operator(n_qudits: int, is_csr: bool = False):\n",
    "    ss = csr_matrix((3**n_qudits, 3**n_qudits), dtype=CDTYPE)\n",
    "    for i in range(n_qudits - 1):\n",
    "        d1, d2 = 3**i, 3**(n_qudits - i - 2)\n",
    "        for j in s_list:\n",
    "            ss += tensor_product_sparse(eye(d1), j, j, eye(d2))\n",
    "    if is_csr:\n",
    "        return ss\n",
    "    return ss.toarray()\n",
    "\n",
    "\n",
    "def qutrit_spin_operator2(n_qudits: int, is_csr: bool = False):\n",
    "    ss = csr_matrix((3**n_qudits, 3**n_qudits), dtype=CDTYPE)\n",
    "    for i in range(n_qudits - 1):\n",
    "        d1, d2 = 3**i, 3**(n_qudits - i - 2)\n",
    "        for j in s2_list:\n",
    "            ss += tensor_product_sparse(eye(d1), j, j, eye(d2))\n",
    "    if is_csr:\n",
    "        return ss\n",
    "    return ss.toarray()\n",
    "\n",
    "\n",
    "def qutrit_Hamiltonian(n_qudits: int, beta: float, is_csr: bool = False):\n",
    "    s1 = qutrit_spin_operator(n_qudits, is_csr=True)\n",
    "    s2 = qutrit_spin_operator2(n_qudits, is_csr=True)\n",
    "    Ham = s1 - beta * s2\n",
    "    if is_csr:\n",
    "        return Ham\n",
    "    return Ham.toarray()\n",
    "\n",
    "\n",
    "def qubit_spin_operator(n_qudits: int, is_csr: bool = False):\n",
    "    ss = csr_matrix((4**n_qudits, 4**n_qudits), dtype=CDTYPE)\n",
    "    for i in range(n_qudits - 1):\n",
    "        d1, d2 = 4**i, 4**(n_qudits - i - 2)\n",
    "        for j in sym_list:\n",
    "            ss += tensor_product_sparse(eye(d1), j, j, eye(d2))\n",
    "    if is_csr:\n",
    "        return ss\n",
    "    return ss.toarray()\n",
    "\n",
    "\n",
    "def qubit_spin_operator2(n_qudits: int, is_csr: bool = False):\n",
    "    ss = csr_matrix((4**n_qudits, 4**n_qudits), dtype=CDTYPE)\n",
    "    for i in range(n_qudits - 1):\n",
    "        d1, d2 = 4**i, 4**(n_qudits - i - 2)\n",
    "        for j in sym2_list:\n",
    "            ss += tensor_product_sparse(eye(d1), j, j, eye(d2))\n",
    "    if is_csr:\n",
    "        return ss\n",
    "    return ss.toarray()\n",
    "\n",
    "\n",
    "def qubit_Hamiltonian(n_qudits: int, beta: float, is_csr: bool = False):\n",
    "    s1 = qubit_spin_operator(n_qudits, is_csr=True)\n",
    "    s2 = qubit_spin_operator2(n_qudits, is_csr=True)\n",
    "    if is_csr:\n",
    "        return s1 - beta * s2\n",
    "    return (s1 - beta * s2).toarray()\n",
    "\n",
    "\n",
    "sx = csr_matrix([[0, 1, 0], [1, 0, 1], [0, 1, 0]]) / np.sqrt(2)\n",
    "sy = csr_matrix([[0, -1j, 0], [1j, 0, -1j], [0, 1j, 0]]) / np.sqrt(2)\n",
    "sz = csr_matrix([[1, 0, 0], [0, 0, 0], [0, 0, -1]])\n",
    "s_list = [sx, sy, sz]\n",
    "s2_list = [i @ j for i in s_list for j in s_list]\n",
    "sym_list = [symmetric_encoding(i, is_csr=True) for i in s_list]\n",
    "sym2_list = [i @ j for i in sym_list for j in sym_list]\n",
    "\n",
    "n_qudits, beta = 7, -0.3\n",
    "Ham = Hamiltonian(n_qudits, beta)\n",
    "h1 = csr_matrix(Ham.matrix())\n",
    "h2 = qubit_Hamiltonian(n_qudits, beta, is_csr=True)\n",
    "h3 = qutrit_Hamiltonian(n_qudits, beta, is_csr=True)\n",
    "\n",
    "v1 = np.sort(eigsh(h2, k=6, which='SA', return_eigenvectors=False))\n",
    "v2 = np.sort(eigsh(h2, k=6, which='SA', return_eigenvectors=False))\n",
    "print(v1)\n",
    "print(v2)\n",
    "np.allclose(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "print('L', end=' 　')\n",
    "beta_list = [-0.3, -0.2, -0.1, 0.0, 0.4]\n",
    "for beta in beta_list:\n",
    "    if beta < 0:\n",
    "        print(f'β = {beta:.2f}', end='　')\n",
    "    else:\n",
    "        print(f'β = +{beta:.2f}', end='　')\n",
    "print('Time')\n",
    "for n_qudits in [4, 5, 6, 7, 8, 9]:\n",
    "    start_nq = time.perf_counter()\n",
    "    print(n_qudits, end=' 　')\n",
    "    s1 = qubit_spin_operator(n_qudits, is_csr=True)\n",
    "    s2 = qubit_spin_operator2(n_qudits, is_csr=True)\n",
    "    for beta in beta_list:\n",
    "        ham = s1 - beta * s2\n",
    "        eigvals = eigsh(ham, k=4, which='SA', return_eigenvectors=False)\n",
    "        eigvals = sorted(eigvals)\n",
    "        vals = np.array(eigvals[:1])\n",
    "        for v1 in eigvals[1:]:\n",
    "            for v2 in vals:\n",
    "                if np.abs(v1 - v2) < 1e-12:\n",
    "                    break\n",
    "            else:\n",
    "                vals = np.append(vals, v1)\n",
    "        diff = vals[0] - vals[1]\n",
    "        print(f'{diff:.6f}', end='　')\n",
    "    end_nq = time.perf_counter()\n",
    "    print(f'{(end_nq-start_nq):.2f}')\n",
    "end = time.perf_counter()\n",
    "total = end - start\n",
    "if total >= 60:\n",
    "    print(f'Total time: {total//60:.0f}m{total%60:.2f}s')\n",
    "else:\n",
    "    print(f'Total time: {total:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sx = {2: np.array([[0, 1], [1, 0]], dtype=CDTYPE) / 2,  \\\n",
    "      3: np.array([[0, 1, 0], [1, 0, 1], [0, 1, 0]], dtype=CDTYPE) / np.sqrt(2)}\n",
    "Sy = {2: np.array([[0, -1j], [1j, 0]], dtype=CDTYPE) / 2, \\\n",
    "      3: np.array([[0, -1j, 0], [1j, 0, -1j], [0, 1j, 0]], dtype=CDTYPE) / np.sqrt(2)}\n",
    "Sz = {2: np.array([[1, 0], [0, -1]], dtype=CDTYPE) / 2, \\\n",
    "      3: np.array([[1, 0, 0], [0, 0, 0], [0, 0, -1]], dtype=CDTYPE)}\n",
    "\n",
    "dim = 3\n",
    "print(Sx[dim])\n",
    "print(Sy[dim])\n",
    "print(Sz[dim])\n",
    "\n",
    "S = Sx[dim] + Sy[dim] + Sz[dim]\n",
    "print(S)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
