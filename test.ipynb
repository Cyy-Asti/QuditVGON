{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import pennylane as qml\n",
    "from typing import List\n",
    "from scipy.linalg import *\n",
    "from scipy.sparse import *\n",
    "from qudit_mapping import *\n",
    "from qutrit_synthesis import *\n",
    "from scipy.sparse.linalg import *\n",
    "from itertools import combinations\n",
    "\n",
    "np.set_printoptions(precision=8, linewidth=200)\n",
    "torch.set_printoptions(precision=8, linewidth=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 202.61121049997746\n",
      "Time: 379.78978580000694\n",
      "Time: 1.426770599995507\n",
      "False 1.000000000000153 [-9.33333333 -9.33333333 -9.33333333 -9.33333333]\n",
      "True 1.0000000000000868 [-9.33333333 -9.33333333 -9.33333333 -9.33333333]\n",
      "False 1.0000000000001097 [-9.33333333 -9.33333333 -9.33333333 -9.33333333]\n",
      "False 1.000000000000096 [-9.33333333 -9.33333333 -9.33333333 -9.33333333]\n",
      "(0, 1) 1.415617490729165e-28\n",
      "(0, 2) 5.426350951734786e-29\n",
      "(0, 3) 3.8319354513687115e-28\n",
      "(1, 2) 5.29163667354637e-28\n",
      "(1, 3) 3.3222773023165915e-29\n",
      "(2, 3) 1.7859399046122164e-28\n",
      "Time: 3.0535957000101916\n"
     ]
    }
   ],
   "source": [
    "def qutrit_spin_operator(n_qudits: int, is_csr: bool = False):\n",
    "    ss = csr_matrix((3**n_qudits, 3**n_qudits), dtype=CDTYPE)\n",
    "    for i in range(n_qudits - 1):\n",
    "        d1, d2 = 3**i, 3**(n_qudits - i - 2)\n",
    "        for j in s_list:\n",
    "            ss += tensor_product_sparse(eye(d1), j, j, eye(d2))\n",
    "    if is_csr:\n",
    "        return ss\n",
    "    return ss.toarray()\n",
    "\n",
    "\n",
    "def qutrit_spin_operator2(n_qudits: int, is_csr: bool = False):\n",
    "    ss = csr_matrix((3**n_qudits, 3**n_qudits), dtype=CDTYPE)\n",
    "    for i in range(n_qudits - 1):\n",
    "        d1, d2 = 3**i, 3**(n_qudits - i - 2)\n",
    "        for j in s2_list:\n",
    "            ss += tensor_product_sparse(eye(d1), j, j, eye(d2))\n",
    "    if is_csr:\n",
    "        return ss\n",
    "    return ss.toarray()\n",
    "\n",
    "\n",
    "def qutrit_Hamiltonian(n_qudits: int, beta: float, is_csr: bool = False):\n",
    "    s1 = qutrit_spin_operator(n_qudits, is_csr=True)\n",
    "    s2 = qutrit_spin_operator2(n_qudits, is_csr=True)\n",
    "    Ham = s1 - beta * s2\n",
    "    if is_csr:\n",
    "        return Ham\n",
    "    return Ham.toarray()\n",
    "\n",
    "\n",
    "sx = csr_matrix([[0, 1, 0], [1, 0, 1], [0, 1, 0]]) / np.sqrt(2)\n",
    "sy = csr_matrix([[0, -1j, 0], [1j, 0, -1j], [0, 1j, 0]]) / np.sqrt(2)\n",
    "sz = csr_matrix([[1, 0, 0], [0, 0, 0], [0, 0, -1]])\n",
    "s_list = [sx, sy, sz]\n",
    "s2_list = [i @ j for i in s_list for j in s_list]\n",
    "sym_list = [symmetric_encoding(i, is_csr=True) for i in s_list]\n",
    "sym2_list = [i @ j for i in sym_list for j in sym_list]\n",
    "\n",
    "beta = -1 / 3\n",
    "n_qudits = 15\n",
    "n_qubits = 2 * n_qudits\n",
    "t1 = time.perf_counter()\n",
    "ham = qutrit_Hamiltonian(n_qudits, beta, is_csr=True)\n",
    "t2 = time.perf_counter()\n",
    "print('Time:', t2 - t1)\n",
    "eigvals, eigvecs = eigsh(ham, k=4, which='SA')\n",
    "t3 = time.perf_counter()\n",
    "print('Time:', t3 - t2)\n",
    "eigvecs = orth(eigvecs)\n",
    "t4 = time.perf_counter()\n",
    "print('Time:', t4 - t3)\n",
    "\n",
    "for i in range(len(eigvals)):\n",
    "    print(np.allclose(ham @ eigvecs[:, i], eigvals[i] * eigvecs[:, i], atol=1e-14), norm(eigvecs[:, i], 2), eigvals)\n",
    "for i in combinations(range(len(eigvals)), 2):\n",
    "    print(i, fidelity(eigvecs[:, i[0]], eigvecs[:, i[1]]))\n",
    "t5 = time.perf_counter()\n",
    "print('Time:', t5 - t4)\n",
    "\n",
    "mat_path = f'./mats/ED_degeneracy.mat'\n",
    "# updatemat(mat_path, {f'nqd{n_qudits}': (eigvals, eigvecs)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20833333333333334 * (X(0) @ X(2)) + 0.20833333333333334 * (X(0) @ X(3)) + 0.20833333333333334 * (X(1) @ X(2)) + 0.20833333333333334 * (X(1) @ X(3)) + 0.20833333333333334 * (Y(0) @ Y(2)) + 0.20833333333333334 * (Y(0) @ Y(3)) + 0.20833333333333334 * (Y(1) @ Y(2)) + 0.20833333333333334 * (Y(1) @ Y(3)) + 0.20833333333333334 * (Z(0) @ Z(2)) + 0.20833333333333334 * (Z(0) @ Z(3)) + 0.20833333333333334 * (Z(1) @ Z(2)) + 0.20833333333333334 * (Z(1) @ Z(3)) + 0.20833333333333334 * (X(2) @ X(4)) + 0.20833333333333334 * (X(2) @ X(5)) + 0.20833333333333334 * (X(3) @ X(4)) + 0.20833333333333334 * (X(3) @ X(5)) + 0.20833333333333334 * (Y(2) @ Y(4)) + 0.20833333333333334 * (Y(2) @ Y(5)) + 0.20833333333333334 * (Y(3) @ Y(4)) + 0.20833333333333334 * (Y(3) @ Y(5)) + 0.20833333333333334 * (Z(2) @ Z(4)) + 0.20833333333333334 * (Z(2) @ Z(5)) + 0.20833333333333334 * (Z(3) @ Z(4)) + 0.20833333333333334 * (Z(3) @ Z(5)) + 0.20833333333333334 * (X(4) @ X(6)) + 0.20833333333333334 * (X(4) @ X(7)) + 0.20833333333333334 * (X(5) @ X(6)) + 0.20833333333333334 * (X(5) @ X(7)) + 0.20833333333333334 * (Y(4) @ Y(6)) + 0.20833333333333334 * (Y(4) @ Y(7)) + 0.20833333333333334 * (Y(5) @ Y(6)) + 0.20833333333333334 * (Y(5) @ Y(7)) + 0.20833333333333334 * (Z(4) @ Z(6)) + 0.20833333333333334 * (Z(4) @ Z(7)) + 0.20833333333333334 * (Z(5) @ Z(6)) + 0.20833333333333334 * (Z(5) @ Z(7)) + 0.20833333333333334 * (X(6) @ X(8)) + 0.20833333333333334 * (X(6) @ X(9)) + 0.20833333333333334 * (X(7) @ X(8)) + 0.20833333333333334 * (X(7) @ X(9)) + 0.20833333333333334 * (Y(6) @ Y(8)) + 0.20833333333333334 * (Y(6) @ Y(9)) + 0.20833333333333334 * (Y(7) @ Y(8)) + 0.20833333333333334 * (Y(7) @ Y(9)) + 0.20833333333333334 * (Z(6) @ Z(8)) + 0.20833333333333334 * (Z(6) @ Z(9)) + 0.20833333333333334 * (Z(7) @ Z(8)) + 0.20833333333333334 * (Z(7) @ Z(9)) + 0.20833333333333334 * (X(8) @ X(10)) + 0.20833333333333334 * (X(8) @ X(11)) + 0.20833333333333334 * (X(9) @ X(10)) + 0.20833333333333334 * (X(9) @ X(11)) + 0.20833333333333334 * (Y(8) @ Y(10)) + 0.20833333333333334 * (Y(8) @ Y(11)) + 0.20833333333333334 * (Y(9) @ Y(10)) + 0.20833333333333334 * (Y(9) @ Y(11)) + 0.20833333333333334 * (Z(8) @ Z(10)) + 0.20833333333333334 * (Z(8) @ Z(11)) + 0.20833333333333334 * (Z(9) @ Z(10)) + 0.20833333333333334 * (Z(9) @ Z(11)) + 1.25 * I() + 0.16666666666666666 * (X(2) @ X(3)) + 0.08333333333333333 * (X(0) @ X(1)) + 0.08333333333333333 * (X(0) @ X(1) @ X(2) @ X(3)) + 0.041666666666666664 * (X(0) @ Y(1) @ X(2) @ Y(3)) + 0.041666666666666664 * (X(0) @ Y(1) @ X(3) @ Y(2)) + 0.041666666666666664 * (X(1) @ Y(0) @ X(2) @ Y(3)) + 0.041666666666666664 * (X(1) @ Y(0) @ X(3) @ Y(2)) + 0.041666666666666664 * (X(0) @ Z(1) @ X(2) @ Z(3)) + 0.041666666666666664 * (X(0) @ Z(1) @ X(3) @ Z(2)) + 0.041666666666666664 * (X(1) @ Z(0) @ X(2) @ Z(3)) + 0.041666666666666664 * (X(1) @ Z(0) @ X(3) @ Z(2)) + 0.16666666666666666 * (Y(2) @ Y(3)) + 0.08333333333333333 * (Y(0) @ Y(1)) + 0.08333333333333333 * (Y(0) @ Y(1) @ Y(2) @ Y(3)) + 0.041666666666666664 * (Y(0) @ Z(1) @ Y(2) @ Z(3)) + 0.041666666666666664 * (Y(0) @ Z(1) @ Y(3) @ Z(2)) + 0.041666666666666664 * (Y(1) @ Z(0) @ Y(2) @ Z(3)) + 0.041666666666666664 * (Y(1) @ Z(0) @ Y(3) @ Z(2)) + 0.16666666666666666 * (Z(2) @ Z(3)) + 0.08333333333333333 * (Z(0) @ Z(1)) + 0.08333333333333333 * (Z(0) @ Z(1) @ Z(2) @ Z(3)) + 0.16666666666666666 * (X(4) @ X(5)) + 0.08333333333333333 * (X(2) @ X(3) @ X(4) @ X(5)) + 0.041666666666666664 * (X(2) @ Y(3) @ X(4) @ Y(5)) + 0.041666666666666664 * (X(2) @ Y(3) @ X(5) @ Y(4)) + 0.041666666666666664 * (X(3) @ Y(2) @ X(4) @ Y(5)) + 0.041666666666666664 * (X(3) @ Y(2) @ X(5) @ Y(4)) + 0.041666666666666664 * (X(2) @ Z(3) @ X(4) @ Z(5)) + 0.041666666666666664 * (X(2) @ Z(3) @ X(5) @ Z(4)) + 0.041666666666666664 * (X(3) @ Z(2) @ X(4) @ Z(5)) + 0.041666666666666664 * (X(3) @ Z(2) @ X(5) @ Z(4)) + 0.16666666666666666 * (Y(4) @ Y(5)) + 0.08333333333333333 * (Y(2) @ Y(3) @ Y(4) @ Y(5)) + 0.041666666666666664 * (Y(2) @ Z(3) @ Y(4) @ Z(5)) + 0.041666666666666664 * (Y(2) @ Z(3) @ Y(5) @ Z(4)) + 0.041666666666666664 * (Y(3) @ Z(2) @ Y(4) @ Z(5)) + 0.041666666666666664 * (Y(3) @ Z(2) @ Y(5) @ Z(4)) + 0.16666666666666666 * (Z(4) @ Z(5)) + 0.08333333333333333 * (Z(2) @ Z(3) @ Z(4) @ Z(5)) + 0.16666666666666666 * (X(6) @ X(7)) + 0.08333333333333333 * (X(4) @ X(5) @ X(6) @ X(7)) + 0.041666666666666664 * (X(4) @ Y(5) @ X(6) @ Y(7)) + 0.041666666666666664 * (X(4) @ Y(5) @ X(7) @ Y(6)) + 0.041666666666666664 * (X(5) @ Y(4) @ X(6) @ Y(7)) + 0.041666666666666664 * (X(5) @ Y(4) @ X(7) @ Y(6)) + 0.041666666666666664 * (X(4) @ Z(5) @ X(6) @ Z(7)) + 0.041666666666666664 * (X(4) @ Z(5) @ X(7) @ Z(6)) + 0.041666666666666664 * (X(5) @ Z(4) @ X(6) @ Z(7)) + 0.041666666666666664 * (X(5) @ Z(4) @ X(7) @ Z(6)) + 0.16666666666666666 * (Y(6) @ Y(7)) + 0.08333333333333333 * (Y(4) @ Y(5) @ Y(6) @ Y(7)) + 0.041666666666666664 * (Y(4) @ Z(5) @ Y(6) @ Z(7)) + 0.041666666666666664 * (Y(4) @ Z(5) @ Y(7) @ Z(6)) + 0.041666666666666664 * (Y(5) @ Z(4) @ Y(6) @ Z(7)) + 0.041666666666666664 * (Y(5) @ Z(4) @ Y(7) @ Z(6)) + 0.16666666666666666 * (Z(6) @ Z(7)) + 0.08333333333333333 * (Z(4) @ Z(5) @ Z(6) @ Z(7)) + 0.16666666666666666 * (X(8) @ X(9)) + 0.08333333333333333 * (X(6) @ X(7) @ X(8) @ X(9)) + 0.041666666666666664 * (X(6) @ Y(7) @ X(8) @ Y(9)) + 0.041666666666666664 * (X(6) @ Y(7) @ X(9) @ Y(8)) + 0.041666666666666664 * (X(7) @ Y(6) @ X(8) @ Y(9)) + 0.041666666666666664 * (X(7) @ Y(6) @ X(9) @ Y(8)) + 0.041666666666666664 * (X(6) @ Z(7) @ X(8) @ Z(9)) + 0.041666666666666664 * (X(6) @ Z(7) @ X(9) @ Z(8)) + 0.041666666666666664 * (X(7) @ Z(6) @ X(8) @ Z(9)) + 0.041666666666666664 * (X(7) @ Z(6) @ X(9) @ Z(8)) + 0.16666666666666666 * (Y(8) @ Y(9)) + 0.08333333333333333 * (Y(6) @ Y(7) @ Y(8) @ Y(9)) + 0.041666666666666664 * (Y(6) @ Z(7) @ Y(8) @ Z(9)) + 0.041666666666666664 * (Y(6) @ Z(7) @ Y(9) @ Z(8)) + 0.041666666666666664 * (Y(7) @ Z(6) @ Y(8) @ Z(9)) + 0.041666666666666664 * (Y(7) @ Z(6) @ Y(9) @ Z(8)) + 0.16666666666666666 * (Z(8) @ Z(9)) + 0.08333333333333333 * (Z(6) @ Z(7) @ Z(8) @ Z(9)) + 0.08333333333333333 * (X(10) @ X(11)) + 0.08333333333333333 * (X(8) @ X(9) @ X(10) @ X(11)) + 0.041666666666666664 * (X(8) @ Y(9) @ X(10) @ Y(11)) + 0.041666666666666664 * (X(8) @ Y(9) @ X(11) @ Y(10)) + 0.041666666666666664 * (X(9) @ Y(8) @ X(10) @ Y(11)) + 0.041666666666666664 * (X(9) @ Y(8) @ X(11) @ Y(10)) + 0.041666666666666664 * (X(8) @ Z(9) @ X(10) @ Z(11)) + 0.041666666666666664 * (X(8) @ Z(9) @ X(11) @ Z(10)) + 0.041666666666666664 * (X(9) @ Z(8) @ X(10) @ Z(11)) + 0.041666666666666664 * (X(9) @ Z(8) @ X(11) @ Z(10)) + 0.08333333333333333 * (Y(10) @ Y(11)) + 0.08333333333333333 * (Y(8) @ Y(9) @ Y(10) @ Y(11)) + 0.041666666666666664 * (Y(8) @ Z(9) @ Y(10) @ Z(11)) + 0.041666666666666664 * (Y(8) @ Z(9) @ Y(11) @ Z(10)) + 0.041666666666666664 * (Y(9) @ Z(8) @ Y(10) @ Z(11)) + 0.041666666666666664 * (Y(9) @ Z(8) @ Y(11) @ Z(10)) + 0.08333333333333333 * (Z(10) @ Z(11)) + 0.08333333333333333 * (Z(8) @ Z(9) @ Z(10) @ Z(11))\n",
      "Loss: 1.82104366364397263212, 1/10, 2.01\n",
      "Loss: 1.74576755042869113943, 2/10, 3.85\n",
      "Loss: 1.67040730726885100488, 3/10, 5.65\n",
      "Loss: 1.59499002015196533755, 4/10, 7.43\n",
      "Loss: 1.51957088365769288352, 5/10, 9.09\n",
      "Loss: 1.44419998376255120931, 6/10, 11.01\n",
      "Loss: 1.36891853414442277170, 7/10, 12.71\n",
      "Loss: 1.29377926801357268083, 8/10, 14.49\n",
      "Loss: 1.21885297122779023837, 9/10, 16.16\n",
      "Loss: 1.14422658373139674026, 10/10, 17.89\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "from typing import List\n",
    "from qutrit_synthesis import NUM_PR, two_qutrit_unitary_synthesis\n",
    "\n",
    "np.set_printoptions(precision=8, linewidth=200)\n",
    "torch.set_printoptions(precision=4, linewidth=200)\n",
    "\n",
    "\n",
    "def running(n_qudits: int, epochs: int):\n",
    "    n_layers = 2\n",
    "    beta = -1 / 3\n",
    "    n_qubits = 2 * n_qudits\n",
    "    dev = qml.device('default.qubit', n_qubits)\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "    def spin_operator(obj: List[int]):\n",
    "        if len(obj) != 2:\n",
    "            raise ValueError(f'The number of object qubits {len(obj)} should be 2')\n",
    "        sx = qml.X(obj[0]) + qml.X(obj[1])\n",
    "        sy = qml.Y(obj[0]) + qml.Y(obj[1])\n",
    "        sz = qml.Z(obj[0]) + qml.Z(obj[1])\n",
    "        return sx, sy, sz\n",
    "\n",
    "    def spin_operator2(obj: List[int]):\n",
    "        if len(obj) != 2:\n",
    "            raise ValueError(f'The number of object qubits {len(obj)} should be 2')\n",
    "        s1 = spin_operator(obj)\n",
    "        s2 = [i @ j for i in s1 for j in s1]\n",
    "        return s2\n",
    "\n",
    "    def Hamiltonian(n_qudits: int, beta: float):\n",
    "        ham1, ham2 = 0, 0\n",
    "        for i in range(n_qudits - 1):\n",
    "            obj1 = [2 * i, 2 * i + 1]\n",
    "            obj2 = [2 * i + 2, 2 * i + 3]\n",
    "            ham1 += qml.sum(*[spin_operator(obj1)[i] @ spin_operator(obj2)[i] for i in range(3)])\n",
    "            ham2 += qml.sum(*[spin_operator2(obj1)[i] @ spin_operator2(obj2)[i] for i in range(9)])\n",
    "        Ham = ham1 / 4 - beta * ham2 / 16\n",
    "        coeffs, obs = qml.simplify(Ham).terms()\n",
    "        coeffs = torch.tensor(coeffs).real\n",
    "        Ham = qml.Hamiltonian(coeffs, obs)\n",
    "        return Ham\n",
    "\n",
    "    def qutrit_symmetric_ansatz(params: torch.Tensor):\n",
    "        for i in range(n_qudits - 1):\n",
    "            obj = list(range(n_qubits - 2 * i - 4, n_qubits - 2 * i))\n",
    "            two_qutrit_unitary_synthesis(params[i], obj)\n",
    "\n",
    "    @qml.qnode(dev, interface='torch', diff_method='best')\n",
    "    def circuit_expval(n_layers: int, params: torch.Tensor, Ham):\n",
    "        params = params.reshape(n_layers, n_qudits - 1, NUM_PR)\n",
    "        qml.layer(qutrit_symmetric_ansatz, n_layers, params)\n",
    "        return qml.expval(Ham)\n",
    "\n",
    "    np.random.seed(42)\n",
    "    n_params = n_layers * (n_qudits - 1) * NUM_PR\n",
    "    params_init = np.random.uniform(-np.pi, np.pi, n_params)\n",
    "    params = torch.tensor(params_init, device=device, requires_grad=True)\n",
    "    optimizer = torch.optim.Adam([params], lr=1e-3)\n",
    "    Ham = Hamiltonian(n_qudits, beta)\n",
    "    print(Ham)\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss = circuit_expval(n_layers, params, Ham)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t = time.perf_counter() - start\n",
    "        print(f'Loss: {loss.item():.20f}, {epoch+1}/{epochs}, {t:.2f}')\n",
    "\n",
    "\n",
    "running(n_qudits=6, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.40869948 -4.40869948 -4.40869948 -4.40233539 -3.68159428 -3.68159428]\n",
      "[-4.40869948 -4.40869948 -4.40869948 -4.40233539 -3.68159428 -3.68159428]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def spin_operator(obj: List[int]):\n",
    "    if len(obj) != 2:\n",
    "        raise ValueError(f'The number of object qubits {len(obj)} should be 2')\n",
    "    sx = qml.X(obj[0]) + qml.X(obj[1])\n",
    "    sy = qml.Y(obj[0]) + qml.Y(obj[1])\n",
    "    sz = qml.Z(obj[0]) + qml.Z(obj[1])\n",
    "    return sx, sy, sz\n",
    "\n",
    "\n",
    "def spin_operator2(obj: List[int]):\n",
    "    if len(obj) != 2:\n",
    "        raise ValueError(f'The number of object qubits {len(obj)} should be 2')\n",
    "    s1 = spin_operator(obj)\n",
    "    s2 = [i @ j for i in s1 for j in s1]\n",
    "    return s2\n",
    "\n",
    "\n",
    "def Hamiltonian(n_qudits: int, beta: float):\n",
    "    ham1, ham2 = 0, 0\n",
    "    for i in range(n_qudits - 1):\n",
    "        obj1 = [2 * i, 2 * i + 1]\n",
    "        obj2 = [2 * i + 2, 2 * i + 3]\n",
    "        ham1 += qml.sum(*[spin_operator(obj1)[i] @ spin_operator(obj2)[i] for i in range(3)])\n",
    "        ham2 += qml.sum(*[spin_operator2(obj1)[i] @ spin_operator2(obj2)[i] for i in range(9)])\n",
    "    Ham = ham1 / 4 - beta * ham2 / 16\n",
    "    coeffs, obs = qml.simplify(Ham).terms()\n",
    "    coeffs = torch.tensor(coeffs).real\n",
    "    Ham = qml.Hamiltonian(coeffs, obs)\n",
    "    return Ham\n",
    "\n",
    "\n",
    "def qutrit_spin_operator(n_qudits: int, is_csr: bool = False):\n",
    "    ss = csr_matrix((3**n_qudits, 3**n_qudits), dtype=CDTYPE)\n",
    "    for i in range(n_qudits - 1):\n",
    "        d1, d2 = 3**i, 3**(n_qudits - i - 2)\n",
    "        for j in s_list:\n",
    "            ss += tensor_product_sparse(eye(d1), j, j, eye(d2))\n",
    "    if is_csr:\n",
    "        return ss\n",
    "    return ss.toarray()\n",
    "\n",
    "\n",
    "def qutrit_spin_operator2(n_qudits: int, is_csr: bool = False):\n",
    "    ss = csr_matrix((3**n_qudits, 3**n_qudits), dtype=CDTYPE)\n",
    "    for i in range(n_qudits - 1):\n",
    "        d1, d2 = 3**i, 3**(n_qudits - i - 2)\n",
    "        for j in s2_list:\n",
    "            ss += tensor_product_sparse(eye(d1), j, j, eye(d2))\n",
    "    if is_csr:\n",
    "        return ss\n",
    "    return ss.toarray()\n",
    "\n",
    "\n",
    "def qutrit_Hamiltonian(n_qudits: int, beta: float, is_csr: bool = False):\n",
    "    s1 = qutrit_spin_operator(n_qudits, is_csr=True)\n",
    "    s2 = qutrit_spin_operator2(n_qudits, is_csr=True)\n",
    "    Ham = s1 - beta * s2\n",
    "    if is_csr:\n",
    "        return Ham\n",
    "    return Ham.toarray()\n",
    "\n",
    "\n",
    "def qubit_spin_operator(n_qudits: int, is_csr: bool = False):\n",
    "    ss = csr_matrix((4**n_qudits, 4**n_qudits), dtype=CDTYPE)\n",
    "    for i in range(n_qudits - 1):\n",
    "        d1, d2 = 4**i, 4**(n_qudits - i - 2)\n",
    "        for j in sym_list:\n",
    "            ss += tensor_product_sparse(eye(d1), j, j, eye(d2))\n",
    "    if is_csr:\n",
    "        return ss\n",
    "    return ss.toarray()\n",
    "\n",
    "\n",
    "def qubit_spin_operator2(n_qudits: int, is_csr: bool = False):\n",
    "    ss = csr_matrix((4**n_qudits, 4**n_qudits), dtype=CDTYPE)\n",
    "    for i in range(n_qudits - 1):\n",
    "        d1, d2 = 4**i, 4**(n_qudits - i - 2)\n",
    "        for j in sym2_list:\n",
    "            ss += tensor_product_sparse(eye(d1), j, j, eye(d2))\n",
    "    if is_csr:\n",
    "        return ss\n",
    "    return ss.toarray()\n",
    "\n",
    "\n",
    "def qubit_Hamiltonian(n_qudits: int, beta: float, is_csr: bool = False):\n",
    "    s1 = qubit_spin_operator(n_qudits, is_csr=True)\n",
    "    s2 = qubit_spin_operator2(n_qudits, is_csr=True)\n",
    "    if is_csr:\n",
    "        return s1 - beta * s2\n",
    "    return (s1 - beta * s2).toarray()\n",
    "\n",
    "\n",
    "sx = csr_matrix([[0, 1, 0], [1, 0, 1], [0, 1, 0]]) / np.sqrt(2)\n",
    "sy = csr_matrix([[0, -1j, 0], [1j, 0, -1j], [0, 1j, 0]]) / np.sqrt(2)\n",
    "sz = csr_matrix([[1, 0, 0], [0, 0, 0], [0, 0, -1]])\n",
    "s_list = [sx, sy, sz]\n",
    "s2_list = [i @ j for i in s_list for j in s_list]\n",
    "sym_list = [symmetric_encoding(i, is_csr=True) for i in s_list]\n",
    "sym2_list = [i @ j for i in sym_list for j in sym_list]\n",
    "\n",
    "n_qudits, beta = 7, -0.3\n",
    "Ham = Hamiltonian(n_qudits, beta)\n",
    "h1 = csr_matrix(Ham.matrix())\n",
    "h2 = qubit_Hamiltonian(n_qudits, beta, is_csr=True)\n",
    "h3 = qutrit_Hamiltonian(n_qudits, beta, is_csr=True)\n",
    "\n",
    "v1 = np.sort(eigsh(h2, k=6, which='SA', return_eigenvectors=False))\n",
    "v2 = np.sort(eigsh(h2, k=6, which='SA', return_eigenvectors=False))\n",
    "print(v1)\n",
    "print(v2)\n",
    "np.allclose(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L 　β = -0.30　β = -0.20　β = -0.10　β = +0.00　β = +0.40　Time\n",
      "4 　-0.039379　-0.171777　-0.329668　-0.509170　-1.331250　0.14\n",
      "5 　-0.023224　-0.147423　-0.328731　-0.546645　-1.603914　0.19\n",
      "6 　-0.011608　-0.082462　-0.184574　-0.307786　-0.927374　1.97\n",
      "7 　-0.006364　-0.066161　-0.178889　-0.330956　-1.153717　4.02\n",
      "8 　-0.003310　-0.040809　-0.110734　-0.201879　-0.696740　12.17\n",
      "9 　-0.001774　-0.031059　-0.102979　-0.212703　-0.877509　48.72\n",
      "Total time: 1m7.19s\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "print('L', end=' 　')\n",
    "beta_list = [-0.3, -0.2, -0.1, 0.0, 0.4]\n",
    "for beta in beta_list:\n",
    "    if beta < 0:\n",
    "        print(f'β = {beta:.2f}', end='　')\n",
    "    else:\n",
    "        print(f'β = +{beta:.2f}', end='　')\n",
    "print('Time')\n",
    "for n_qudits in [4, 5, 6, 7, 8, 9]:\n",
    "    start_nq = time.perf_counter()\n",
    "    print(n_qudits, end=' 　')\n",
    "    s1 = qubit_spin_operator(n_qudits, is_csr=True)\n",
    "    s2 = qubit_spin_operator2(n_qudits, is_csr=True)\n",
    "    for beta in beta_list:\n",
    "        ham = s1 - beta * s2\n",
    "        eigvals = eigsh(ham, k=4, which='SA', return_eigenvectors=False)\n",
    "        eigvals = sorted(eigvals)\n",
    "        vals = np.array(eigvals[:1])\n",
    "        for v1 in eigvals[1:]:\n",
    "            for v2 in vals:\n",
    "                if np.abs(v1 - v2) < 1e-12:\n",
    "                    break\n",
    "            else:\n",
    "                vals = np.append(vals, v1)\n",
    "        diff = vals[0] - vals[1]\n",
    "        print(f'{diff:.6f}', end='　')\n",
    "    end_nq = time.perf_counter()\n",
    "    print(f'{(end_nq-start_nq):.2f}')\n",
    "end = time.perf_counter()\n",
    "total = end - start\n",
    "if total >= 60:\n",
    "    print(f'Total time: {total//60:.0f}m{total%60:.2f}s')\n",
    "else:\n",
    "    print(f'Total time: {total:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "from typing import List\n",
    "from utils import updatemat\n",
    "from qutrit_synthesis import NUM_PR, two_qutrit_unitary_synthesis\n",
    "\n",
    "np.set_printoptions(precision=8, linewidth=200)\n",
    "torch.set_printoptions(precision=8, linewidth=200)\n",
    "\n",
    "\n",
    "def spin_operator(obj: List[int]):\n",
    "    if len(obj) != 2:\n",
    "        raise ValueError(f'The number of object qubits {len(obj)} should be 2')\n",
    "    sx = qml.X(obj[0]) / 2 + qml.X(obj[1]) / 2\n",
    "    sy = qml.Y(obj[0]) / 2 + qml.Y(obj[1]) / 2\n",
    "    sz = qml.Z(obj[0]) / 2 + qml.Z(obj[1]) / 2\n",
    "    return sx + sy + sz\n",
    "\n",
    "\n",
    "def spin_operator2(obj: List[int]):\n",
    "    if len(obj) != 2:\n",
    "        raise ValueError(f'The number of object qubits {len(obj)} should be 2')\n",
    "    s1 = qml.X(obj[0]) + qml.Y(obj[0]) + qml.Z(obj[0])\n",
    "    s2 = qml.X(obj[1]) + qml.Y(obj[1]) + qml.Z(obj[1])\n",
    "    return 3 / 2 * qml.I(obj) + (s1 @ s2) / 2\n",
    "\n",
    "\n",
    "def Hamiltonian(n_qudits: int, beta: float):\n",
    "    Ham = 0\n",
    "    for i in range(n_qudits - 1):\n",
    "        obj1 = [2 * i, 2 * i + 1]\n",
    "        obj2 = [2 * i + 2, 2 * i + 3]\n",
    "        Ham += spin_operator(obj1) @ spin_operator(obj2)\n",
    "        Ham -= beta * (spin_operator2(obj1) @ spin_operator2(obj2))\n",
    "    return Ham\n",
    "\n",
    "\n",
    "def qutrit_symmetric_ansatz(n_qudits: int, params: torch.Tensor, Ham):\n",
    "    params = params.reshape(n_qudits - 1, NUM_PR)\n",
    "    n_qubits = 2 * n_qudits\n",
    "    for i in range(n_qudits - 1):\n",
    "        obj = list(range(n_qubits - 2 * i - 4, n_qubits - 2 * i))\n",
    "        two_qutrit_unitary_synthesis(params[i], obj)\n",
    "    return qml.expval(Ham)\n",
    "\n",
    "\n",
    "n_qudits, beta, epochs, lr = 4, -0.3, 10, 0.1\n",
    "\n",
    "n_qubits = 2 * n_qudits\n",
    "dev = qml.device('default.qubit', n_qubits)\n",
    "print(f'Coefficient beta: {beta}')\n",
    "print(f'Number of qudits: {n_qudits}')\n",
    "print(f'Number of qubits: {n_qubits}')\n",
    "\n",
    "if torch.cuda.is_available() and n_qubits > 14:\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f'PyTorch Device: {device}')\n",
    "\n",
    "pr_num = (n_qudits - 1) * NUM_PR\n",
    "init_params = np.random.uniform(-np.pi, np.pi, pr_num)\n",
    "params = torch.tensor(init_params, device=device, requires_grad=True)\n",
    "cost_fn = qml.QNode(qutrit_symmetric_ansatz, dev, interface='torch')\n",
    "optimizer = torch.optim.Adam([params], lr=lr)\n",
    "Ham = Hamiltonian(n_qudits, beta)\n",
    "\n",
    "start = time.perf_counter()\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    loss = cost_fn(n_qudits, params, Ham)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    count = epoch + 1\n",
    "    if count % 10 == 0:\n",
    "        t = time.perf_counter() - start\n",
    "        print(f'Loss: {loss.item():.20f}, {count}/{epochs}, {t:.2f}')\n",
    "\n",
    "loss_res = loss.detach().cpu()\n",
    "params_res = optimizer.param_groups[0]['params'][0].detach().cpu()\n",
    "time_str = time.strftime('%Y%m%d_%H%M%S', time.localtime())\n",
    "mat_dict = {'n_qudits': n_qudits, 'n_qubits': n_qubits, 'beta': beta, 'epochs': epochs, \\\n",
    "'learning_rate': lr, 'params_init': init_params, 'params_res': params_res, 'loss': loss_res}\n",
    "# updatemat(f'./mats/testVQE_{time_str}.mat', mat_dict)\n",
    "print(mat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of qudits: 2\n",
      "Number of qubits: 4\n",
      "PyTorch Device: cpu\n",
      " 10/100, Loss: 0.11452233784747231637, 1.92\n",
      " 20/100, Loss: 0.04348994287393345010, 3.78\n",
      " 30/100, Loss: 0.01553885829701937005, 5.67\n",
      " 40/100, Loss: 0.00298989540027944783, 7.62\n",
      " 50/100, Loss: 0.00208902553650319386, 9.45\n",
      " 60/100, Loss: 0.00076402399449075273, 11.29\n",
      " 70/100, Loss: 0.00005343525472996033, 13.24\n",
      " 80/100, Loss: 0.00005210247622969288, 15.09\n",
      " 90/100, Loss: 0.00004616149155771410, 16.96\n",
      "100/100, Loss: 0.00001883485911411201, 18.88\n",
      "tensor([-0.7883,  3.1787,  1.5731,  0.7353, -2.4910, -1.7185, -2.3456,  2.5369,\n",
      "         0.1404,  1.3074, -3.0123,  2.9525,  2.5515, -2.1499, -2.6950, -2.5657,\n",
      "        -0.8062,  0.4495, -0.0290, -1.0358,  1.0673, -2.2651, -1.3060, -0.8397,\n",
      "        -0.4823,  1.7283, -2.2659,  0.4237,  0.2579, -2.5819,  1.0432, -1.5874,\n",
      "        -2.9493,  2.8204,  2.9257,  2.0735, -1.3506, -2.2652,  0.9351, -0.1973,\n",
      "        -2.5656, -0.2673, -3.3031,  2.8470, -1.5156,  1.0212, -1.1831, -0.1073,\n",
      "         0.2107, -2.1438,  3.2910,  1.4006,  2.6226,  2.7211,  0.8534,  2.9372,\n",
      "        -2.4758, -2.1542, -3.0894, -0.7405, -0.8382, -1.5186,  1.9681, -0.8296,\n",
      "        -1.2466,  0.3601, -2.0795,  2.0764, -2.9221,  3.4289,  1.6482, -1.5921,\n",
      "        -3.3663,  1.7783,  1.0701,  0.9409,  1.6686, -2.3603, -1.1291, -2.8633,\n",
      "         1.8318,  0.3250, -1.0038, -2.6933, -1.4211, -0.8999,  1.1469,  0.3032,\n",
      "         2.6121,  0.1969, -2.6955,  1.5209,  1.2486,  0.1338,  1.4045,  0.5345,\n",
      "         0.6348, -1.4186, -2.8724, -2.5690, -2.7379,  0.9690],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "from typing import List\n",
    "from utils import updatemat\n",
    "from qutrit_synthesis import NUM_PR, two_qutrit_unitary_synthesis\n",
    "\n",
    "\n",
    "def spin_operator(obj: List[int]):\n",
    "    if len(obj) != 2:\n",
    "        raise ValueError(f'The number of object qubits {len(obj)} should be 2')\n",
    "    sx = qml.X(obj[0]) / 2 + qml.X(obj[1]) / 2\n",
    "    sy = qml.Y(obj[0]) / 2 + qml.Y(obj[1]) / 2\n",
    "    sz = qml.Z(obj[0]) / 2 + qml.Z(obj[1]) / 2\n",
    "    return sx + sy + sz\n",
    "\n",
    "\n",
    "def spin_operator2(obj: List[int]):\n",
    "    if len(obj) != 2:\n",
    "        raise ValueError(f'The number of object qubits {len(obj)} should be 2')\n",
    "    s1 = qml.X(obj[0]) + qml.Y(obj[0]) + qml.Z(obj[0])\n",
    "    s2 = qml.X(obj[1]) + qml.Y(obj[1]) + qml.Z(obj[1])\n",
    "    return 3 / 2 * qml.I(obj) + (s1 @ s2) / 2\n",
    "\n",
    "\n",
    "def Hamiltonian(n_qudits: int, beta: float):\n",
    "    Ham = 0\n",
    "    for i in range(n_qudits - 1):\n",
    "        obj1 = [2 * i, 2 * i + 1]\n",
    "        obj2 = [2 * i + 2, 2 * i + 3]\n",
    "        Ham += spin_operator(obj1) @ spin_operator(obj2)\n",
    "        Ham -= beta * (spin_operator2(obj1) @ spin_operator2(obj2))\n",
    "    return Ham\n",
    "\n",
    "\n",
    "def qutrit_symmetric_ansatz(n_qudits: int, params: torch.Tensor, Ham):\n",
    "    params = params.reshape(n_qudits - 1, NUM_PR)\n",
    "    n_qubits = 2 * n_qudits\n",
    "    for i in range(n_qudits - 1):\n",
    "        obj = list(range(n_qubits - 2 * i - 4, n_qubits - 2 * i))\n",
    "        two_qutrit_unitary_synthesis(params[i], obj)\n",
    "    return qml.expval(Ham)\n",
    "\n",
    "\n",
    "n_qudits = 2\n",
    "n_qubits = 2 * n_qudits\n",
    "dev = qml.device('default.qubit', n_qubits)\n",
    "print(f'Number of qudits: {n_qudits}')\n",
    "print(f'Number of qubits: {n_qubits}')\n",
    "\n",
    "if torch.cuda.is_available() and n_qubits > 14:\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f'PyTorch Device: {device}')\n",
    "\n",
    "np.random.seed(42)\n",
    "pr_num = (n_qudits - 1) * NUM_PR\n",
    "init_params = np.random.uniform(-np.pi, np.pi, pr_num)\n",
    "params = torch.tensor(init_params, device=device, requires_grad=True)\n",
    "cost_fn = qml.QNode(qutrit_symmetric_ansatz, dev, interface='torch')\n",
    "optimizer = torch.optim.Adam([params], lr=0.1)\n",
    "Ham = Hamiltonian(n_qudits, beta=-1 / 3)\n",
    "\n",
    "epochs = 100\n",
    "start = time.perf_counter()\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    loss = cost_fn(n_qudits, params, Ham)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    count = epoch + 1\n",
    "    if count % 10 == 0:\n",
    "        t = time.perf_counter() - start\n",
    "        print(f'{count:3d}/{epochs}, Loss: {loss.item():.20f}, {t:.2f}')\n",
    "params_res = optimizer.param_groups[0]['params'][0].detach()\n",
    "print(params_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0, 1] [2, 3]\n",
      "[[-3. +0.j  -0.5+0.5j -0.5+0.5j  0. +0.j  -0.5+0.5j  0. +0.j   0. +2.j   0.5+0.5j -0.5+0.5j  0. +2.j   0. +0.j   0.5+0.5j  0. +0.j   0.5+0.5j  0.5+0.5j  1. +0.j ]\n",
      " [-0.5-0.5j -2. +0.j   0. +0.j  -0.5+0.5j  0. +0.j  -0.5+0.5j -0.5+0.5j  0. +1.j  -2. +0.j   1.5-1.5j -0.5+0.5j  0. -1.j  -0.5+0.5j  0. -1.j   0. +1.j  -0.5-0.5j]\n",
      " [-0.5-0.5j  0. +0.j  -2. +0.j  -0.5+0.5j -2. +0.j  -0.5+0.5j  1.5-1.5j  0. -1.j   0. +0.j  -0.5+0.5j -0.5+0.5j  0. +1.j  -0.5+0.5j  0. +1.j   0. -1.j  -0.5-0.5j]\n",
      " [ 0. +0.j  -0.5-0.5j -0.5-0.5j -1. +0.j  -0.5-0.5j -1. +0.j   1. +0.j   0.5-0.5j -0.5-0.5j  1. +0.j  -1. +0.j   0.5-0.5j -1. +0.j   0.5-0.5j  0.5-0.5j  0. +0.j ]\n",
      " [-0.5-0.5j  0. +0.j  -2. +0.j  -0.5+0.5j -2. +0.j  -0.5+0.5j  1.5-1.5j  0. -1.j   0. +0.j  -0.5+0.5j -0.5+0.5j  0. +1.j  -0.5+0.5j  0. +1.j   0. -1.j  -0.5-0.5j]\n",
      " [ 0. +0.j  -0.5-0.5j -0.5-0.5j -1. +0.j  -0.5-0.5j -1. +0.j   1. +0.j   0.5-0.5j -0.5-0.5j  1. +0.j  -1. +0.j   0.5-0.5j -1. +0.j   0.5-0.5j  0.5-0.5j  0. +0.j ]\n",
      " [ 0. -2.j  -0.5-0.5j  1.5+1.5j  1. +0.j   1.5+1.5j  1. +0.j  -5. +0.j  -1.5+1.5j -0.5-0.5j -1. +0.j   1. +0.j   0.5-0.5j  1. +0.j   0.5-0.5j -1.5+1.5j  0. +2.j ]\n",
      " [ 0.5-0.5j  0. -1.j   0. +1.j   0.5+0.5j  0. +1.j   0.5+0.5j -1.5-1.5j -2. +0.j   0. -1.j   0.5+0.5j  0.5+0.5j  0. +0.j   0.5+0.5j  0. +0.j  -2. +0.j   0.5-0.5j]\n",
      " [-0.5-0.5j -2. +0.j   0. +0.j  -0.5+0.5j  0. +0.j  -0.5+0.5j -0.5+0.5j  0. +1.j  -2. +0.j   1.5-1.5j -0.5+0.5j  0. -1.j  -0.5+0.5j  0. -1.j   0. +1.j  -0.5-0.5j]\n",
      " [ 0. -2.j   1.5+1.5j -0.5-0.5j  1. +0.j  -0.5-0.5j  1. +0.j  -1. +0.j   0.5-0.5j  1.5+1.5j -5. +0.j   1. +0.j  -1.5+1.5j  1. +0.j  -1.5+1.5j  0.5-0.5j  0. +2.j ]\n",
      " [ 0. +0.j  -0.5-0.5j -0.5-0.5j -1. +0.j  -0.5-0.5j -1. +0.j   1. +0.j   0.5-0.5j -0.5-0.5j  1. +0.j  -1. +0.j   0.5-0.5j -1. +0.j   0.5-0.5j  0.5-0.5j  0. +0.j ]\n",
      " [ 0.5-0.5j  0. +1.j   0. -1.j   0.5+0.5j  0. -1.j   0.5+0.5j  0.5+0.5j  0. +0.j   0. +1.j  -1.5-1.5j  0.5+0.5j -2. +0.j   0.5+0.5j -2. +0.j   0. +0.j   0.5-0.5j]\n",
      " [ 0. +0.j  -0.5-0.5j -0.5-0.5j -1. +0.j  -0.5-0.5j -1. +0.j   1. +0.j   0.5-0.5j -0.5-0.5j  1. +0.j  -1. +0.j   0.5-0.5j -1. +0.j   0.5-0.5j  0.5-0.5j  0. +0.j ]\n",
      " [ 0.5-0.5j  0. +1.j   0. -1.j   0.5+0.5j  0. -1.j   0.5+0.5j  0.5+0.5j  0. +0.j   0. +1.j  -1.5-1.5j  0.5+0.5j -2. +0.j   0.5+0.5j -2. +0.j   0. +0.j   0.5-0.5j]\n",
      " [ 0.5-0.5j  0. -1.j   0. +1.j   0.5+0.5j  0. +1.j   0.5+0.5j -1.5-1.5j -2. +0.j   0. -1.j   0.5+0.5j  0.5+0.5j  0. +0.j   0.5+0.5j  0. +0.j  -2. +0.j   0.5-0.5j]\n",
      " [ 1. +0.j  -0.5+0.5j -0.5+0.5j  0. +0.j  -0.5+0.5j  0. +0.j   0. -2.j   0.5+0.5j -0.5+0.5j  0. -2.j   0. +0.j   0.5+0.5j  0. +0.j   0.5+0.5j  0.5+0.5j -3. +0.j ]] (16, 16)\n"
     ]
    }
   ],
   "source": [
    "def spin_operator(obj: List[int]):\n",
    "    if len(obj) != 2:\n",
    "        raise ValueError(f'The number of object qubits {len(obj)} should be 2')\n",
    "    sx = qml.X(obj[0]) / 2 + qml.X(obj[1]) / 2\n",
    "    sy = qml.Y(obj[0]) / 2 + qml.Y(obj[1]) / 2\n",
    "    sz = qml.Z(obj[0]) / 2 + qml.Z(obj[1]) / 2\n",
    "    return sx + sy + sz\n",
    "\n",
    "\n",
    "def spin_operator2(obj: List[int]):\n",
    "    if len(obj) != 2:\n",
    "        raise ValueError(f'The number of object qubits {len(obj)} should be 2')\n",
    "    s1 = qml.X(obj[0]) + qml.Y(obj[0]) + qml.Z(obj[0])\n",
    "    s2 = qml.X(obj[1]) + qml.Y(obj[1]) + qml.Z(obj[1])\n",
    "    return 3 / 2 * qml.I(obj) + (s1 @ s2) / 2\n",
    "\n",
    "\n",
    "def Hamiltonian(n_qudits: int, beta: float):\n",
    "    Ham = 0\n",
    "    for i in range(n_qudits - 1):\n",
    "        obj1 = [2 * i, 2 * i + 1]\n",
    "        obj2 = [2 * i + 2, 2 * i + 3]\n",
    "        Ham += spin_operator(obj1) @ spin_operator(obj2)\n",
    "        Ham -= beta * (spin_operator2(obj1) @ spin_operator2(obj2))\n",
    "        print(i, obj1, obj2)\n",
    "    return Ham\n",
    "\n",
    "\n",
    "n_qudits = 2\n",
    "Ham = Hamiltonian(n_qudits, 1)\n",
    "Ham_mat = Ham.matrix()\n",
    "print(Ham_mat, Ham_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.        +0.j 0.70710678+0.j 0.        +0.j]\n",
      " [0.70710678+0.j 0.        +0.j 0.70710678+0.j]\n",
      " [0.        +0.j 0.70710678+0.j 0.        +0.j]]\n",
      "[[ 0.+0.j         -0.-0.70710678j  0.+0.j        ]\n",
      " [ 0.+0.70710678j  0.+0.j         -0.-0.70710678j]\n",
      " [ 0.+0.j          0.+0.70710678j  0.+0.j        ]]\n",
      "[[ 1.+0.j  0.+0.j  0.+0.j]\n",
      " [ 0.+0.j  0.+0.j  0.+0.j]\n",
      " [ 0.+0.j  0.+0.j -1.+0.j]]\n",
      "[[ 1.        +0.j          0.70710678-0.70710678j  0.        +0.j        ]\n",
      " [ 0.70710678+0.70710678j  0.        +0.j          0.70710678-0.70710678j]\n",
      " [ 0.        +0.j          0.70710678+0.70710678j -1.        +0.j        ]]\n"
     ]
    }
   ],
   "source": [
    "Sx = {2: np.array([[0, 1], [1, 0]], dtype=CDTYPE) / 2,  \\\n",
    "      3: np.array([[0, 1, 0], [1, 0, 1], [0, 1, 0]], dtype=CDTYPE) / np.sqrt(2)}\n",
    "Sy = {2: np.array([[0, -1j], [1j, 0]], dtype=CDTYPE) / 2, \\\n",
    "      3: np.array([[0, -1j, 0], [1j, 0, -1j], [0, 1j, 0]], dtype=CDTYPE) / np.sqrt(2)}\n",
    "Sz = {2: np.array([[1, 0], [0, -1]], dtype=CDTYPE) / 2, \\\n",
    "      3: np.array([[1, 0, 0], [0, 0, 0], [0, 0, -1]], dtype=CDTYPE)}\n",
    "\n",
    "dim = 3\n",
    "print(Sx[dim])\n",
    "print(Sy[dim])\n",
    "print(Sz[dim])\n",
    "\n",
    "S = Sx[dim] + Sy[dim] + Sz[dim]\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from h5py import File\n",
    "import pennylane as qml\n",
    "from qudit_mapping import symmetric_encoding\n",
    "from qutrit_synthesis import NUM_PR, two_qutrit_unitary_synthesis\n",
    "\n",
    "path = '../QuditVQE/data_232/from_classical_to_violation_dense'\n",
    "s = File(f'{path}/232_d3_D9_model1216_RDM2_iter1_target_state_vector.mat')\n",
    "state = s['target_state_vec'][:].view('complex')\n",
    "n_qudits = s['N'][0]\n",
    "s.close()\n",
    "\n",
    "dim = 3\n",
    "n_qubits = n_qudits * (dim - 1)\n",
    "dev = qml.device('default.qubit', n_qubits)\n",
    "print(f'Number of qudits: {n_qudits}')\n",
    "print(f'Number of qubits: {n_qubits}')\n",
    "\n",
    "if torch.cuda.is_available() and n_qubits > 14:\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f'PyTorch Device: {device}')\n",
    "\n",
    "psi_sym = symmetric_encoding(state, n_qudits)\n",
    "psi_sym = torch.from_numpy(psi_sym)\n",
    "\n",
    "pr_num = (n_qudits - 1) * NUM_PR\n",
    "init_params = np.random.uniform(-np.pi, np.pi, pr_num)\n",
    "params = torch.tensor(init_params, device=device, requires_grad=True)\n",
    "optimizer = torch.optim.Adam([params], lr=0.1)\n",
    "\n",
    "\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def qutrit_symmetric_ansatz(params: torch.Tensor):\n",
    "    params = params.reshape(n_qudits - 1, NUM_PR)\n",
    "    for i in range(n_qudits - 1):\n",
    "        obj = list(range(n_qubits - (dim - 1) * (i + 2), n_qubits - (dim - 1) * i))\n",
    "        two_qutrit_unitary_synthesis(params[i], obj)\n",
    "    return qml.state()\n",
    "\n",
    "\n",
    "def cost_fn(params: torch.Tensor):\n",
    "    psi_circ = qutrit_symmetric_ansatz(params)\n",
    "    fidelity = torch.abs(psi_circ.conj() @ psi_sym)**2\n",
    "    return fidelity\n",
    "\n",
    "\n",
    "epochs = 500\n",
    "start = time.perf_counter()\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    loss = cost_fn(params)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    count = epoch + 1\n",
    "    if count % 10 == 0:\n",
    "        t = time.perf_counter() - start\n",
    "        print(f'{count:3d}/{epochs}, Loss: {loss.item():.15f}, Fidelity: {1-loss.item():.15f}, {t:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
